{% extends 'base.html.twig' %}

{% block body %}
    <div>
        <p>
            The App will work with two different modalities: as patient’s voice amplifier and as simultaneous translator
            of a limited vocabulary of ho short commands (e.g. “I’m thirsty”, “how are you?”, etc.). The App will be
            able to recognize that vocabulary through a set of Machine Learning algorithms implemented through the
            Google’s TensorFlow engine. The commands’ recognition will be fostered by periodic retraining sessions, at
            the end of them, the software will have adapted itself to the progressive impairment of patients’ voice.
    </div>
    <div>
        <p>
            A peculiar App characteristic will thus be the possibility to recognize only the commands trained by the
            user. Accordingly, App will adapt to the unique features of the App user’s voice, without relying on
            external databases.
        </p>
    </div>
    <div>
        <p>
            The App is presently under development, once completed i twill be validated in a ALS patient cohort in the
            SLA center of Hospital San Raffaele, Milan, Italy.
        </p>
    </div>
    <div>
        <p>
            We plan to distribute the App in the second trimester of 2018.
        </p>
    </div>
    <div>
        <p>
            For every kind of request, please do not hesitate in contacting the project PI at the following email
            address: info@allspeak.eu
        </p>
    </div>
{% endblock %}
