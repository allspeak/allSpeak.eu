{% extends 'base.html.twig' %}

{% block body %}
    <div class="row index">
        <div class="col-sm-offset-1 col-sm-10">
            <h2 class="text-center">Il progetto</h2>
            <div>
                <p>
                    AllSpeak è un <a href="http://www.arisla.org/wp-content/uploads/2015/12/ALLSpeak.pdf">progetto</a>
                    in fase di realizzazione presso l’<a
                            href="https://iit.it/lines/robotics-brain-and-cognitive-sciences">Unità Robotics, Brain and
                        Cognitive Sciences (RBCS)</a>
                    dell’<a href="https://iit.it">Istituto Italiano di Tecnologia (IIT)</a> di Genova. Il progetto è
                    stato finanziato dalla
                    <a href="http://www.arisla.org/">Fondazione Italiana di Ricerca per la Sclerosi Laterale Amiotrofica
                        (ARISLA)</a>, utilizzando i proventi
                    della campagna <a href="https://en.wikipedia.org/wiki/Ice_Bucket_Challenge">Ice Bucket Challenge</a>
                    2015, promossa ad organizzata dall’<a href="www.aisla.it">Associazione Italiana Sclerosi Laterale
                        Amiotrofica (AISLA)</a>.
                </p>
            </div>
            <div>
                <p>
                    AllSpeak sarà un App per smartphone Android in grado di aiutare il paziente SLA a comunicare
                    verbalmente i
                    propri bisogni primari. L’App funzionerà secondo due modalità: come amplificatore della voce del
                    paziente e come
                    traduttore istantaneo di una limitato vocabolario di parole o brevi frasi (es. Ho sete, Come stai?
                    etc.). L’App
                    sarà in grado di riconoscere tale vocabolario di frasi attraverso una serie di sofisticati algoritmi
                    di Machine
                    Learning ivi inclusi e tramite delle periodiche sessioni di addestramento, al termine delle quali,
                    il software
                    avrà adattato la propria base dati al progressivo deterioramento della voce dei pazienti.
                </p>
            </div>
            <div>
                <p>
                    Caratteristica peculiare dell’App sarà quindi la possibilità di riconoscere solo ed esclusivamente
                    quelle frasi che un determinato soggetto avrà addestrato. Obiettivo del progetto è quello quindi di
                    permettere all’App di plasmarsi sulle caratteristiche uniche della voce del suo utilizzatore, senza
                    ricorrere a base dati esterne. Una volta terminata, L’App verrà prima validata su una popolazione di
                    pazienti SLA reclutata dal Centro SLA dell’Ospedale San Raffaele di Milano, e poi distribuita
                    gratuitamente attraverso il consueto canale Play Store di Google.
                </p>
            </div>
            <div>
                <p>
                    Prevediamo di essere poter distribuire l’App dopo il secondo trimestre del 2018.
                </p>
            </div>
            <div>
                <p>
                    Per qualunque necessità, non esitate a contattare il responsabile del progetto al seguente
                    indirizzo: <a href="mailto:info@allspeak.eu">info@allspeak.eu</a>
                </p>
            </div>
            <div>
                <p>
                    Partecipanti al progetto:
                </p>
                <ul>
                    <li>
                        Ing. Alberto Inuggi: Investigatore principale del progetto (IIT)
                    </li>
                    <li>
                        Ing. Leonardo Badino: Responsabile algoritmi riconoscimento vocale (IIT@CTNSC)
                    </li>
                    <li>
                        M.D. Nilo Riva: responsabile Centro SLA, Ospedale San Raffaele di Milano
                    </li>
                    <li>
                        Dr. Ilaria Mauri: logopedista, Ospedale San Raffaele di Milano
                    </li>
                    <li>
                        Dr. Cecilia di Nardi: sviluppatrice software nell’ambito del riconoscimento vocale.
                    </li>
                    <li>
                        Federico Bozzini: sviluppatore WEB
                    </li>
                </ul>
            </div>
            <div class="partners-section">
                <h4>Partners</h4>
                <div class="row partners">
                    <div class="col-xs-offset-1 col-xs-4 col-sm-offset-0 col-sm-3">
                        <a href="http://www.arisla.org/" class="thumbnail">
                            <img src="{{ asset('dist/img/arislaLogo.jpg') }}" alt="Logo Arisla">
                        </a>
                    </div>
                    <div class="col-xs-offset-2 col-xs-4 col-sm-offset-0 col-sm-3">
                        <a href="http://iit.it" class="thumbnail">
                            <img src="{{ asset('dist/img/iitLogo.jpg') }}" alt="Logo IIT">
                        </a>
                    </div>
                    <div class="col-xs-offset-1 col-xs-4 col-sm-offset-0 col-sm-3">
                        <a href="http://www.hsr.it/" class="thumbnail">
                            <img src="{{ asset('dist/img/osrLogo.jpg') }}" alt="Logo OSR">
                        </a>
                    </div>
                    <div class="col-xs-offset-2 col-xs-4 col-sm-offset-0 col-sm-3">
                        <a href="http://www.aisla.it/" class="thumbnail">
                            <img src="{{ asset('dist/img/aislaLogo.jpg') }}" alt="Logo AISLA">
                        </a>
                    </div>
                </div>
            </div>
        </div>
    </div>
{% endblock %}